# Overview
京都芸術大学通信教育部のWebサイトに公開されているシラバス情報を自動的に収集し、構造化されたデータとしてGoogleスプレッドシートまたはCSVファイルに出力するスクレイピングツールを開発する。本ツールは、学科・コース・科目の階層構造を再帰的に辿りながら、全科目の詳細情報を効率的に収集し、教職員や学生が活用しやすい形式で提供することを目的とする。

# Core Features

## 1. 階層的Webスクレイピング機能
- 学科・コース一覧ページから全24件の学科情報を取得
- 各学科・コースごとの科目一覧ページを自動巡回
- 各科目の詳細ページから必要な情報を抽出
- サブカテゴリやネストされた構造にも対応

## 2. データ抽出・解析機能
- HTML構造から必要な情報を正確に抽出
- 年度、科目コード、科目名、単位数など16項目以上のデータを収集
- HTMLの構造変化に対する柔軟な対応
- エラーハンドリングと欠損データの適切な処理

## 3. データ出力・整形機能
- Googleスプレッドシートへの直接出力
- CSV形式でのローカル保存
- データの重複排除と整合性チェック
- 階層構造を反映した分かりやすいデータ構造

## 4. 進捗管理・ログ機能
- スクレイピング進捗のリアルタイム表示
- エラーログと成功ログの分離記録
- 中断・再開機能によるレジューム対応
- 処理統計情報の出力

# User Experience

## ユーザーペルソナ
- **教職員**: シラバス情報を横断的に分析・管理したい大学関係者
- **システム管理者**: 定期的にシラバス情報を更新・管理する担当者
- **研究者・学生**: 科目情報を効率的に検索・比較したい利用者

## 主要なユーザーフロー
1. **初回セットアップ**
   - 設定ファイルの作成（認証情報、出力先など）
   - Google API認証の設定（スプレッドシート出力の場合）

2. **スクレイピング実行**
   - コマンドラインから実行コマンドを入力
   - 進捗バーで処理状況を確認
   - エラー発生時は詳細なメッセージを表示

3. **結果確認**
   - 出力されたスプレッドシート/CSVファイルを開く
   - データの完全性と正確性を確認
   - 必要に応じて再実行や部分実行

## UI/UX考慮事項
- シンプルで直感的なCLIインターフェース
- 進捗状況の視覚的なフィードバック
- エラーメッセージの分かりやすさ
- 設定ファイルによる柔軟なカスタマイズ

# Technical Architecture

## システムコンポーネント
- **スクレイパーエンジン**: BeautifulSoup4 + httpxによる非同期処理
- **データパーサー**: 構造化データ抽出モジュール
- **データストア**: 一時的なSQLiteデータベース
- **出力エンジン**: Google Sheets API / pandas DataFrame
- **設定管理**: YAML/TOML形式の設定ファイル

## データモデル
```
Course {
  id: string
  department: string
  course_name: string
  url: string
}

Subject {
  year: int
  category: string
  code: string
  name: string
  credits: int
  classification: string
  term: string
  instructors: string[]
  schedule: string
  location: string
  description: text
  evaluation_method: text
  prerequisites: text
  preparation_review: text
  references: text
  syllabus_plan: text
  course_id: foreign_key
}
```

## APIと統合
- Google Sheets API v4（認証フロー含む）
- httpx/aiohttpによる非同期HTTP通信
- Retry機構とRate limiting対応

## インフラ要件
- Python 3.12実行環境
- 最低2GBのメモリ
- 安定したインターネット接続
- Google Cloud Platform認証情報（オプション）

# Development Roadmap

## Phase 1: MVP（基本機能実装）
- 環境セットアップとプロジェクト構造の確立
- 基本的なWebスクレイピング機能の実装
- 単一ページからのデータ抽出機能
- CSV出力機能の実装
- エラーハンドリングの基礎実装

## Phase 2: 階層構造対応
- 再帰的なページ巡回機能の実装
- 学科→コース→科目の階層構造解析
- データベースを使用した中間データ管理
- 進捗管理とログ機能の実装

## Phase 3: 高度な機能実装
- Google Sheets API統合
- 非同期処理による高速化
- 中断・再開機能の実装
- 設定ファイルによるカスタマイズ機能

## Phase 4: 最適化と拡張
- パフォーマンス最適化
- より詳細なエラーハンドリング
- データ検証と品質保証機能
- ドキュメントとテストの充実

# Logical Dependency Chain

1. **基盤構築**
   - プロジェクト初期化とuv環境セットアップ
   - 基本的なHTTPリクエスト機能

2. **データ抽出の実装**
   - 単一ページのHTML解析
   - 必要項目の抽出ロジック

3. **階層的クロール機能**
   - URLパターンの解析
   - 再帰的なページ訪問ロジック

4. **データ永続化**
   - SQLiteデータベース統合
   - データモデルの実装

5. **出力機能**
   - CSV出力の実装（MVP）
   - Google Sheets統合（拡張機能）

6. **運用機能**
   - エラーハンドリングとリトライ
   - ログと進捗管理

# Risks and Mitigations

## 技術的課題
- **Webサイト構造の変更**: 定期的な監視とパーサーの更新体制
- **アクセス制限やレート制限**: 適切な遅延とリトライ機構の実装
- **大量データの処理**: 非同期処理とメモリ効率的な実装

## MVP範囲の決定
- 最初はCSV出力のみに限定し、動作確認を優先
- 基本的な項目抽出から始め、段階的に項目を追加
- エラー処理は最小限から始め、実際の問題に応じて拡張

## リソース制約
- 開発期間: 段階的リリースによる早期価値提供
- 技術的複雑性: 既存ライブラリの活用とシンプルな設計

# Appendix

## 技術仕様詳細
- Python 3.12 + uv パッケージマネージャー
- 主要ライブラリ: httpx, beautifulsoup4, pandas, google-api-python-client
- 非同期処理: asyncio + httpx
- データベース: SQLite3（ローカル処理用）

## URL構造の詳細
- 学科一覧: `https://w.guide.air-u.kyoto-art.ac.jp/syllabus/index.html`
- 科目一覧: `https://w.guide.air-u.kyoto-art.ac.jp/syllabus/course.html?cid={course_id}`
- 科目詳細: `https://w.guide.air-u.kyoto-art.ac.jp/syllabus/detail.html?page=detail&code={subject_code}&cid={course_id}`

## 抽出対象項目一覧
1. 年度
2. 科目群区分
3. 科目コード
4. 科目名
5. 単位数
6. 分類
7. 開講期
8. 担当者名
9. 開催日程
10. 開催地
11. 科目概要・到達目標
12. 成績評価の方法
13. 履修の前提条件
14. 予習・復習
15. 参考文献
16. 授業計画
17. その他抽出可能な追加情報 